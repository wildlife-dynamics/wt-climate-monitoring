# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details
import json
import os

from ecoscope_workflows_core.tasks.config import (
    set_workflow_details as set_workflow_details,
)
from ecoscope_workflows_core.tasks.filter import (
    get_timezone_from_time_range as get_timezone_from_time_range,
)
from ecoscope_workflows_core.tasks.filter import set_time_range as set_time_range
from ecoscope_workflows_core.tasks.groupby import set_groupers as set_groupers
from ecoscope_workflows_core.tasks.groupby import split_groups as split_groups
from ecoscope_workflows_core.tasks.io import persist_text as persist_text
from ecoscope_workflows_core.tasks.io import set_er_connection as set_er_connection
from ecoscope_workflows_core.tasks.results import (
    create_plot_widget_single_view as create_plot_widget_single_view,
)
from ecoscope_workflows_core.tasks.results import gather_dashboard as gather_dashboard
from ecoscope_workflows_core.tasks.results import (
    merge_widget_views as merge_widget_views,
)
from ecoscope_workflows_core.tasks.transformation import (
    add_temporal_index as add_temporal_index,
)
from ecoscope_workflows_core.tasks.transformation import (
    convert_values_to_timezone as convert_values_to_timezone,
)
from ecoscope_workflows_core.tasks.transformation import (
    extract_column_as_type as extract_column_as_type,
)
from ecoscope_workflows_core.tasks.transformation import map_columns as map_columns
from ecoscope_workflows_ext_custom.tasks.io import (
    persist_df_wrapper as persist_df_wrapper,
)
from ecoscope_workflows_ext_custom.tasks.transformation import (
    drop_column_prefix as drop_column_prefix,
)
from ecoscope_workflows_ext_custom.tasks.transformation import (
    filter_row_values as filter_row_values,
)
from ecoscope_workflows_ext_ecoscope.tasks.analysis import summarize_df as summarize_df
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_subjectgroup_observations as get_subjectgroup_observations,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    draw_line_chart as draw_line_chart,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    normalize_json_column as normalize_json_column,
)

from ..params import Params


def main(params: Params):
    params_dict = json.loads(params.model_dump_json(exclude_unset=True))

    workflow_details = (
        set_workflow_details.validate()
        .set_task_instance_id("workflow_details")
        .handle_errors()
        .with_tracing()
        .partial(**(params_dict.get("workflow_details") or {}))
        .call()
    )

    time_range = (
        set_time_range.validate()
        .set_task_instance_id("time_range")
        .handle_errors()
        .with_tracing()
        .partial(
            time_format="%d %b %Y %H:%M:%S %Z", **(params_dict.get("time_range") or {})
        )
        .call()
    )

    get_timezone = (
        get_timezone_from_time_range.validate()
        .set_task_instance_id("get_timezone")
        .handle_errors()
        .with_tracing()
        .partial(time_range=time_range, **(params_dict.get("get_timezone") or {}))
        .call()
    )

    er_client_name = (
        set_er_connection.validate()
        .set_task_instance_id("er_client_name")
        .handle_errors()
        .with_tracing()
        .partial(**(params_dict.get("er_client_name") or {}))
        .call()
    )

    subject_obs = (
        get_subjectgroup_observations.validate()
        .set_task_instance_id("subject_obs")
        .handle_errors()
        .with_tracing()
        .partial(
            client=er_client_name,
            time_range=time_range,
            raise_on_empty=True,
            include_details=True,
            include_subjectsource_details=True,
            **(params_dict.get("subject_obs") or {}),
        )
        .call()
    )

    drop_extra_prefix = (
        drop_column_prefix.validate()
        .set_task_instance_id("drop_extra_prefix")
        .handle_errors()
        .with_tracing()
        .partial(
            df=subject_obs,
            prefix="extra__",
            duplicate_strategy="suffix",
            **(params_dict.get("drop_extra_prefix") or {}),
        )
        .call()
    )

    process_columns = (
        map_columns.validate()
        .set_task_instance_id("process_columns")
        .handle_errors()
        .with_tracing()
        .partial(
            df=drop_extra_prefix,
            drop_columns=[],
            retain_columns=[
                "id",
                "subject_id",
                "created_at",
                "recorded_at",
                "source",
                "device_status_properties",
                "observation_details",
                "geometry",
                "subject__name",
            ],
            rename_columns={"subject__name": "weather_station"},
            **(params_dict.get("process_columns") or {}),
        )
        .call()
    )

    convert_to_user_timezone = (
        convert_values_to_timezone.validate()
        .set_task_instance_id("convert_to_user_timezone")
        .handle_errors()
        .with_tracing()
        .partial(
            df=process_columns,
            timezone=get_timezone,
            columns=["time"],
            **(params_dict.get("convert_to_user_timezone") or {}),
        )
        .call()
    )

    normalize_obs_details = (
        normalize_json_column.validate()
        .set_task_instance_id("normalize_obs_details")
        .handle_errors()
        .with_tracing()
        .partial(
            df=convert_to_user_timezone,
            column="observation_details",
            skip_if_not_exists=False,
            sort_columns=True,
            **(params_dict.get("normalize_obs_details") or {}),
        )
        .call()
    )

    drop_obs_details_prefix = (
        drop_column_prefix.validate()
        .set_task_instance_id("drop_obs_details_prefix")
        .handle_errors()
        .with_tracing()
        .partial(
            df=normalize_obs_details,
            prefix="observation_details__",
            duplicate_strategy="suffix",
            **(params_dict.get("drop_obs_details_prefix") or {}),
        )
        .call()
    )

    extract_date = (
        extract_column_as_type.validate()
        .set_task_instance_id("extract_date")
        .handle_errors()
        .with_tracing()
        .partial(
            df=drop_obs_details_prefix,
            column_name="recorded_at",
            output_type="date",
            output_column_name="date",
            **(params_dict.get("extract_date") or {}),
        )
        .call()
    )

    filtered_weather_station = (
        filter_row_values.validate()
        .set_task_instance_id("filtered_weather_station")
        .handle_errors()
        .with_tracing()
        .partial(
            df=extract_date,
            column="weather_station",
            **(params_dict.get("filtered_weather_station") or {}),
        )
        .call()
    )

    groupers = (
        set_groupers.validate()
        .set_task_instance_id("groupers")
        .handle_errors()
        .with_tracing()
        .partial(**(params_dict.get("groupers") or {}))
        .call()
    )

    df_with_temporal_index = (
        add_temporal_index.validate()
        .set_task_instance_id("df_with_temporal_index")
        .handle_errors()
        .with_tracing()
        .partial(
            df=filtered_weather_station,
            time_col="recorded_at",
            groupers=groupers,
            cast_to_datetime=True,
            format="mixed",
            **(params_dict.get("df_with_temporal_index") or {}),
        )
        .call()
    )

    split_weather_groups = (
        split_groups.validate()
        .set_task_instance_id("split_weather_groups")
        .handle_errors()
        .with_tracing()
        .partial(
            df=df_with_temporal_index,
            groupers=groupers,
            **(params_dict.get("split_weather_groups") or {}),
        )
        .call()
    )

    persist_observations = (
        persist_df_wrapper.validate()
        .set_task_instance_id("persist_observations")
        .handle_errors()
        .with_tracing()
        .partial(
            root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            sanitize=True,
            **(params_dict.get("persist_observations") or {}),
        )
        .mapvalues(argnames=["df"], argvalues=split_weather_groups)
    )

    daily_weather = (
        summarize_df.validate()
        .set_task_instance_id("daily_weather")
        .handle_errors()
        .with_tracing()
        .partial(
            groupby_cols=["weather_station", "date"],
            summary_params=[
                {
                    "display_name": "daily_precipitation",
                    "aggregator": "sum",
                    "column": "precipitation",
                },
                {
                    "display_name": "daily_temperature",
                    "aggregator": "mean",
                    "column": "surface_air_temperature",
                },
            ],
            reset_index=True,
            **(params_dict.get("daily_weather") or {}),
        )
        .mapvalues(argnames=["df"], argvalues=split_weather_groups)
    )

    persist_daily_summary = (
        persist_df_wrapper.validate()
        .set_task_instance_id("persist_daily_summary")
        .handle_errors()
        .with_tracing()
        .partial(
            root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            filetypes=["csv"],
            sanitize=False,
            **(params_dict.get("persist_daily_summary") or {}),
        )
        .mapvalues(argnames=["df"], argvalues=daily_weather)
    )

    precipitation_chart = (
        draw_line_chart.validate()
        .set_task_instance_id("precipitation_chart")
        .handle_errors()
        .with_tracing()
        .partial(
            x_column="date",
            y_column="daily_precipitation",
            category_column="weather_station",
            line_kwargs={"shape": "hvh"},
            layout_kwargs={
                "xaxis": {"title": "Date"},
                "yaxis": {"title": "Precipitation (mm)"},
                "legend_title": "Weather Station",
                "hovermode": "closest",
            },
            **(params_dict.get("precipitation_chart") or {}),
        )
        .mapvalues(argnames=["dataframe"], argvalues=daily_weather)
    )

    persist_precipitation = (
        persist_text.validate()
        .set_task_instance_id("persist_precipitation")
        .handle_errors()
        .with_tracing()
        .partial(
            root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            **(params_dict.get("persist_precipitation") or {}),
        )
        .mapvalues(argnames=["text"], argvalues=precipitation_chart)
    )

    precipitation_chart_widget = (
        create_plot_widget_single_view.validate()
        .set_task_instance_id("precipitation_chart_widget")
        .handle_errors()
        .with_tracing()
        .partial(
            title="Daily Precipitation by Station",
            **(params_dict.get("precipitation_chart_widget") or {}),
        )
        .map(argnames=["view", "data"], argvalues=persist_precipitation)
    )

    grouped_precipitation_widget = (
        merge_widget_views.validate()
        .set_task_instance_id("grouped_precipitation_widget")
        .handle_errors()
        .with_tracing()
        .partial(
            widgets=precipitation_chart_widget,
            **(params_dict.get("grouped_precipitation_widget") or {}),
        )
        .call()
    )

    temperature_chart = (
        draw_line_chart.validate()
        .set_task_instance_id("temperature_chart")
        .handle_errors()
        .with_tracing()
        .partial(
            x_column="date",
            y_column="daily_temperature",
            category_column="weather_station",
            line_kwargs={"shape": "spline"},
            layout_kwargs={
                "xaxis": {"title": "Date"},
                "yaxis": {"title": "Average Daily Temperature (Celsius)"},
                "legend_title": "Weather Station",
                "hovermode": "closest",
            },
            **(params_dict.get("temperature_chart") or {}),
        )
        .mapvalues(argnames=["dataframe"], argvalues=daily_weather)
    )

    persist_temperature = (
        persist_text.validate()
        .set_task_instance_id("persist_temperature")
        .handle_errors()
        .with_tracing()
        .partial(
            root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            **(params_dict.get("persist_temperature") or {}),
        )
        .mapvalues(argnames=["text"], argvalues=temperature_chart)
    )

    temperature_chart_widget = (
        create_plot_widget_single_view.validate()
        .set_task_instance_id("temperature_chart_widget")
        .handle_errors()
        .with_tracing()
        .partial(
            title="Daily Temperature by Station",
            **(params_dict.get("temperature_chart_widget") or {}),
        )
        .map(argnames=["view", "data"], argvalues=persist_temperature)
    )

    grouped_temperature_widget = (
        merge_widget_views.validate()
        .set_task_instance_id("grouped_temperature_widget")
        .handle_errors()
        .with_tracing()
        .partial(
            widgets=temperature_chart_widget,
            **(params_dict.get("grouped_temperature_widget") or {}),
        )
        .call()
    )

    weather_dashboard = (
        gather_dashboard.validate()
        .set_task_instance_id("weather_dashboard")
        .handle_errors()
        .with_tracing()
        .partial(
            details=workflow_details,
            widgets=[grouped_precipitation_widget, grouped_temperature_widget],
            time_range=time_range,
            groupers=groupers,
            **(params_dict.get("weather_dashboard") or {}),
        )
        .call()
    )

    return weather_dashboard
